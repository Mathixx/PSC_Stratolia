# -*- coding: utf-8 -*-
"""Training

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zslO_89CoMvaPhukRpgR-g6by_QLThf1
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
import math
from torch.utils.data import Dataset
import pickle
import datetime
import pandas as pd

if(torch.cuda.is_available()):
    dev = torch.device("cuda")
else:
    dev = torch.device("cpu")
print(dev)

def train_model(net, trainset, save_file, dev = 'cuda', saves = 1000, prints = 200,lr = 0.001,iter = 50, batch_size = 32, num_workers = 0):
  optimizer = optim.Adam(net.parameters(), lr=lr)
  criterion = nn.CrossEntropyLoss().to(dev)
  for epoch in range(iter):  # loop over the dataset multiple times
      running_loss = 0.0
      trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                            shuffle=True, num_workers=num_workers)
      for i, train_data in enumerate(trainloader, 0):
        try:
          inputs, labels = train_data
          inputs = inputs.float().to(dev)
          labels = labels.to(dev)
          optimizer.zero_grad()
          outputs = net(inputs)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()

          running_loss += loss.item()
          if i % prints == prints-1:    # print every 2000 mini-batches
              print('[%d, %5d] loss: %.3f' %
                    (epoch + 1, i + 1, running_loss / 200))
              running_loss = 0.0
          if i % saves == saves-1:    # print every 2000 mini-batches
                torch.save({
              'epoch': epoch,
              'model_state_dict': net.state_dict(),
              'optimizer_state_dict': optimizer.state_dict(),
              'loss': loss,
              }, save_file)
        except Exception as e:
          print(e)

def test_model(net,trainset, dev = 'cuda', iters = 1000,batch_size = 32, num_workers = 0):
  correct = 0
  total = 0
  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                            shuffle=True, num_workers=0)
  with torch.no_grad():
      for i in range(1000):
          data_training = next(iter(trainloader))
          images, labels = data_training
          images = images.float().to(dev)
          labels = labels.to(dev)
          outputs = net(images)
          predicted = torch.argmax(torch.softmax(outputs.data, 1),axis =1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

  print('Accuracy of the network : %d %%' % (
      100 * correct / total))
      
      
      
def train_model_load(net, trainset, save_file, dev = 'cuda', saves = 1000, prints = 200,lr = 0.001,iter = 50, batch_size = 32, num_workers = 0):
  checkpoint = torch.load(save_file)
  net.load_state_dict(checkpoint['model_state_dict'])
  optimizer = optim.Adam(net.parameters(), lr=lr)
  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
  epoch = checkpoint['epoch']
  loss = checkpoint['loss']
  criterion = nn.CrossEntropyLoss().to(dev)
  for epoch in range(iter):  # loop over the dataset multiple times
      running_loss = 0.0
      trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                            shuffle=True, num_workers=num_workers)
      for i, train_data in enumerate(trainloader, 0):
        try:
          inputs, labels = train_data
          inputs = inputs.float().to(dev)
          labels = labels.to(dev)
          optimizer.zero_grad()
          outputs = net(inputs)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()

          running_loss += loss.item()
          if i % prints == prints-1:    # print every 2000 mini-batches
              print('[%d, %5d] loss: %.3f' %
                    (epoch + 1, i + 1, running_loss / 200))
              running_loss = 0.0
          if i % saves == saves-1:    # print every 2000 mini-batches
                torch.save({
              'epoch': epoch,
              'model_state_dict': net.state_dict(),
              'optimizer_state_dict': optimizer.state_dict(),
              'loss': loss,
              }, save_file)
        except Exception as e:
          print(e)