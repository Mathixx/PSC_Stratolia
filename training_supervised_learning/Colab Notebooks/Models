{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MTkEkZhB7-cH"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","from torch.utils.data import Dataset\n","import pickle\n","import datetime\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cn8Ivs8cg0YV"},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dropout):\n","        super(ResBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","\n","        self.bn1.weight.data.fill_(1)\n","        self.bn1.bias.data.zero_()\n","        self.bn2.weight.data.fill_(1)\n","        self.bn2.bias.data.zero_()\n","\n","    def forward(self, x):\n","        identity = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","        out = self.dropout(out)\n","        return out\n","\n","class ProjectedResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dropout):\n","        super(ProjectedResBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, 1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 2, padding)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","        self.projector = nn.Conv2d(in_channels,in_channels,kernel_size, stride = 2 , padding = padding)\n","        self.Conv1x1 = nn.Conv2d(in_channels, out_channels, 1, 1, 0)\n","        self.bn1.weight.data.fill_(1)\n","        self.bn1.bias.data.zero_()\n","        self.bn2.weight.data.fill_(1)\n","        self.bn2.bias.data.zero_()\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        identity = self.projector(x)\n","        identity =  self.Conv1x1(identity)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x += identity\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYtIPzne7-cL"},"outputs":[],"source":["class Net12D(nn.Module):\n","    def __init__(self , dir_number = 8, print_shape=False):\n","        self.print_shape = print_shape\n","        dropoutr = 0.2\n","        super(Net12D, self).__init__()\n","        self.layers1 = nn.ModuleList( [\n","        nn.Conv3d(2, 64, (17,1,1)),\n","        nn.BatchNorm3d(64),\n","        nn.ReLU(),\n","        nn.Dropout(dropoutr),\n","        nn.Conv3d(64, 64, (1,3,3), padding=(0,1,1)),\n","        nn.BatchNorm3d(64),\n","        nn.ReLU(),\n","        nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))])\n","        self.layersRES = nn.ModuleList( [ResBlock(64,64, (3,3), 1, 1, dropoutr),\n","        ResBlock(64,64, (3,3), 1, 1, dropoutr),\n","        ProjectedResBlock(64,128, (3,3), 1, 1, dropoutr),\n","        ResBlock(128,128, (3,3), 1, 1, dropoutr),\n","        ResBlock(128,128, (3,3), 1, 1, dropoutr),\n","        ProjectedResBlock(128,256, (3,3), 1, 1, dropoutr),\n","        ResBlock(256,256, (3,3), 1, 1, dropoutr),\n","        ResBlock(256,256, (3,3), 1, 1, dropoutr),\n","        ProjectedResBlock(256,512, (3,3), 1, 0, dropoutr),\n","        ResBlock(512,512, (3,3), 1, 1, dropoutr),\n","        ResBlock(512,512, (3,3), 1, 1, dropoutr),\n","        nn.Conv2d(512, 512, kernel_size = (2,2), stride = (2,2)),\n","        nn.BatchNorm2d(512),\n","        nn.Dropout(dropoutr)])\n","\n","        self.layers = nn.ModuleList([\n","        nn.Linear(4096, 2048),\n","        nn.BatchNorm1d(2048),\n","        nn.ReLU(),\n","        nn.Dropout(dropoutr),\n","        nn.Linear(2048, 1024),\n","        nn.BatchNorm1d(1024),\n","        nn.ReLU(),\n","        nn.Dropout(dropoutr),\n","        nn.Linear(1024, 1024),\n","        nn.BatchNorm1d(1024),\n","        nn.ReLU(),\n","        nn.Dropout(dropoutr),\n","        nn.Linear(1024, 512),\n","        nn.BatchNorm1d(512),\n","        nn.ReLU(),\n","        nn.Dropout(dropoutr),\n","        nn.Linear(512, dir_number)])\n","\n","        for l in self.layers1:\n","            if isinstance(l, (nn.BatchNorm2d, nn.BatchNorm1d)):\n","                l.weight.data.fill_(1)\n","                l.bias.data.zero_()\n","\n","\n","        for l in self.layers:\n","            if isinstance(l, (nn.BatchNorm2d, nn.BatchNorm1d)):\n","                l.weight.data.fill_(1)\n","                l.bias.data.zero_()\n","            elif isinstance(l, nn.Conv2d):\n","                n = l.kernel_size[0] * l.kernel_size[1] * l.out_channels\n","                l.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(l, nn.Linear):\n","                nn.init.xavier_normal(l.weight)\n","\n","    def forward(self, x):\n","        x = x[:,0,:,:,:,:]\n","        for l in self.layers1:\n","            x = l(x)\n","            if  (isinstance(l , ProjectedResBlock) or  isinstance(l , ResBlock) or  isinstance(l , nn.Dropout) ) and self.print_shape:\n","                print(x.shape)\n","        x = x[:,:,0,:,:]\n","        for l in self.layersRES :\n","            x = l(x)\n","            if  (isinstance(l , ProjectedResBlock) or  isinstance(l , ResBlock) or  isinstance(l , nn.Dropout) ) and self.print_shape:\n","                print(x.shape)\n","        x = torch.flatten(x, 1)\n","        for l in self.layers:\n","            x = l(x)\n","            if isinstance(l , nn.Dropout) and self.print_shape:\n","                print(x.shape)\n","        return x"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1a6ZXyviUEmXDLu7bjAoLyMWY4jNVZZUk","timestamp":1714002906782}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}