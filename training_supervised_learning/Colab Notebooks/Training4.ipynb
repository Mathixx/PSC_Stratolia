{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3531,"status":"ok","timestamp":1715987302844,"user":{"displayName":"Moncef Djafri","userId":"09780211288987995701"},"user_tz":-120},"id":"jiHrdSf07-cJ","outputId":"4e2dad96-600d-45b2-82a5-c3ed72f036c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","\n","if(torch.cuda.is_available()):\n","    dev = torch.device(\"cuda\")\n","else:\n","    dev = torch.device(\"cpu\")\n","print(dev)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25276,"status":"ok","timestamp":1715987453060,"user":{"displayName":"Moncef Djafri","userId":"09780211288987995701"},"user_tz":-120},"id":"8f7HFPj98A3d","outputId":"19ea1be7-6cc4-4782-f18a-8e984a24f890"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n","from models import NetBT\n","import getdata\n","import training"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39477,"status":"ok","timestamp":1715987492533,"user":{"displayName":"Moncef Djafri","userId":"09780211288987995701"},"user_tz":-120},"id":"ZzV2GfcFs9Xm","outputId":"b03bf7b2-66d7-4e8a-d1bb-40083ad2a8fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["17841\n","100429\n","172733\n","417196\n","643632\n","748103\n","2814188\n","4829088\n"]}],"source":["trainset = getdata.get_data()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2048,"status":"ok","timestamp":1715987494577,"user":{"displayName":"Moncef Djafri","userId":"09780211288987995701"},"user_tz":-120},"id":"FhAAHsDXtObk","outputId":"3210bfbb-0bdc-4536-e18d-d6f6cbfa6e79"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/models.py:308: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  nn.init.xavier_normal(l.weight)\n"]}],"source":["net = NetBT()\n","net = net.to(dev)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7957894,"status":"error","timestamp":1715970725445,"user":{"displayName":"Moncef Djafri","userId":"09780211288987995701"},"user_tz":-120},"id":"aRnes9MNuUbI","outputId":"82a16f7d-c4e7-4e76-b94a-33f475de9726"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   200] loss: 2.269\n","[1,   400] loss: 2.112\n","[1,   600] loss: 2.068\n","[1,   800] loss: 2.050\n","[1,  1000] loss: 2.032\n","[1,  1200] loss: 2.021\n","[1,  1400] loss: 2.012\n","[1,  1600] loss: 1.994\n","[1,  1800] loss: 1.988\n","[1,  2000] loss: 1.959\n","[1,  2200] loss: 1.955\n","[1,  2400] loss: 1.935\n","[1,  2600] loss: 1.934\n","[1,  2800] loss: 1.928\n","[1,  3000] loss: 1.913\n","[1,  3200] loss: 1.892\n","[1,  3400] loss: 1.895\n","[1,  3600] loss: 1.898\n","[1,  3800] loss: 1.890\n","[1,  4000] loss: 1.889\n","[1,  4200] loss: 1.878\n","[1,  4400] loss: 1.879\n","[1,  4600] loss: 1.863\n","[1,  4800] loss: 1.870\n","[1,  5000] loss: 1.867\n","[1,  5200] loss: 1.866\n","[1,  5400] loss: 1.858\n","[1,  5600] loss: 1.852\n","[1,  5800] loss: 1.856\n","[1,  6000] loss: 1.855\n","[1,  6200] loss: 1.847\n","[1,  6400] loss: 1.852\n","[1,  6600] loss: 1.851\n","[1,  6800] loss: 1.845\n","[1,  7000] loss: 1.844\n","[1,  7200] loss: 1.843\n","[1,  7400] loss: 1.842\n","[1,  7600] loss: 1.838\n","[1,  7800] loss: 1.844\n","[1,  8000] loss: 1.842\n","[1,  8200] loss: 1.839\n","[1,  8400] loss: 1.846\n","[1,  8600] loss: 1.830\n","[1,  8800] loss: 1.828\n","[1,  9000] loss: 1.835\n","[1,  9200] loss: 1.840\n","[1,  9400] loss: 1.834\n","[1,  9600] loss: 1.818\n","[1,  9800] loss: 1.824\n","[1, 10000] loss: 1.817\n","[1, 10200] loss: 1.799\n","[1, 10400] loss: 1.774\n","[1, 10600] loss: 1.753\n","[1, 10800] loss: 1.732\n","[1, 11000] loss: 1.708\n","[1, 11200] loss: 1.696\n","[1, 11400] loss: 1.685\n","[1, 11600] loss: 1.668\n","[1, 11800] loss: 1.642\n","[1, 12000] loss: 1.640\n","[1, 12200] loss: 1.639\n","[1, 12400] loss: 1.613\n","[1, 12600] loss: 1.607\n","[1, 12800] loss: 1.599\n","[1, 13000] loss: 1.594\n","[1, 13200] loss: 1.578\n","[1, 13400] loss: 1.568\n","[1, 13600] loss: 1.564\n","[1, 13800] loss: 1.551\n","[1, 14000] loss: 1.549\n","[1, 14200] loss: 1.549\n","[1, 14400] loss: 1.541\n","[1, 14600] loss: 1.528\n","[1, 14800] loss: 1.523\n","[1, 15000] loss: 1.513\n","[1, 15200] loss: 1.526\n","[1, 15400] loss: 1.513\n","[1, 15600] loss: 1.506\n","[1, 15800] loss: 1.495\n","[1, 16000] loss: 1.492\n","[1, 16200] loss: 1.489\n","[1, 16400] loss: 1.497\n","[1, 16600] loss: 1.475\n","[1, 16800] loss: 1.463\n","[1, 17000] loss: 1.469\n","[1, 17200] loss: 1.478\n","[1, 17400] loss: 1.465\n","[1, 17600] loss: 1.462\n","[1, 17800] loss: 1.444\n","[1, 18000] loss: 1.449\n","[1, 18200] loss: 1.463\n","[1, 18400] loss: 1.442\n","[1, 18600] loss: 1.449\n","[1, 18800] loss: 1.446\n","[1, 19000] loss: 1.438\n","[1, 19200] loss: 1.439\n","[1, 19400] loss: 1.427\n","[1, 19600] loss: 1.429\n","[1, 19800] loss: 1.429\n","[1, 20000] loss: 1.433\n","[1, 20200] loss: 1.422\n","[1, 20400] loss: 1.413\n","[1, 20600] loss: 1.423\n","[1, 20800] loss: 1.423\n","[1, 21000] loss: 1.401\n","[1, 21200] loss: 1.415\n","[1, 21400] loss: 1.415\n","[1, 21600] loss: 1.406\n","[1, 21800] loss: 1.403\n","[1, 22000] loss: 1.401\n","[1, 22200] loss: 1.400\n","[1, 22400] loss: 1.398\n","[1, 22600] loss: 1.384\n","[1, 22800] loss: 1.381\n","[1, 23000] loss: 1.378\n","[1, 23200] loss: 1.392\n","[1, 23400] loss: 1.379\n","[1, 23600] loss: 1.379\n","[1, 23800] loss: 1.385\n","[1, 24000] loss: 1.369\n","[1, 24200] loss: 1.371\n","[1, 24400] loss: 1.368\n","[1, 24600] loss: 1.375\n","[1, 24800] loss: 1.379\n","[1, 25000] loss: 1.358\n","[1, 25200] loss: 1.373\n","[1, 25400] loss: 1.373\n","[1, 25600] loss: 1.357\n","[1, 25800] loss: 1.362\n","[1, 26000] loss: 1.359\n","[1, 26200] loss: 1.366\n","[1, 26400] loss: 1.357\n","[1, 26600] loss: 1.351\n","[1, 26800] loss: 1.359\n","[1, 27000] loss: 1.349\n","[1, 27200] loss: 1.338\n","[1, 27400] loss: 1.346\n","[1, 27600] loss: 1.343\n","[1, 27800] loss: 1.347\n","[1, 28000] loss: 1.340\n","[1, 28200] loss: 1.335\n","[1, 28400] loss: 1.338\n","[1, 28600] loss: 1.337\n","[1, 28800] loss: 1.333\n","[1, 29000] loss: 1.334\n","[1, 29200] loss: 1.335\n","[1, 29400] loss: 1.328\n","[1, 29600] loss: 1.328\n","[1, 29800] loss: 1.321\n","[1, 30000] loss: 1.322\n","[1, 30200] loss: 1.322\n","[1, 30400] loss: 1.333\n","[1, 30600] loss: 1.321\n","[1, 30800] loss: 1.325\n","[1, 31000] loss: 1.323\n","[1, 31200] loss: 1.314\n","[1, 31400] loss: 1.305\n","[1, 31600] loss: 1.303\n","[1, 31800] loss: 1.310\n","[1, 32000] loss: 1.310\n","[1, 32200] loss: 1.302\n","[1, 32400] loss: 1.324\n","[1, 32600] loss: 1.305\n","[1, 32800] loss: 1.307\n","[1, 33000] loss: 1.301\n","[1, 33200] loss: 1.298\n","[1, 33400] loss: 1.299\n","[1, 33600] loss: 1.303\n","[1, 33800] loss: 1.294\n","[1, 34000] loss: 1.304\n","[1, 34200] loss: 1.291\n","[1, 34400] loss: 1.301\n","[1, 34600] loss: 1.300\n","[1, 34800] loss: 1.294\n","[1, 35000] loss: 1.294\n","[1, 35200] loss: 1.283\n","[1, 35400] loss: 1.295\n","[1, 35600] loss: 1.280\n","[1, 35800] loss: 1.284\n","[1, 36000] loss: 1.292\n","[1, 36200] loss: 1.287\n","[1, 36400] loss: 1.292\n","[1, 36600] loss: 1.284\n","[1, 36800] loss: 1.282\n","[1, 37000] loss: 1.280\n","[1, 37200] loss: 1.287\n","[1, 37400] loss: 1.268\n","[1, 37600] loss: 1.279\n","[1, 37800] loss: 1.262\n","[1, 38000] loss: 1.272\n","[1, 38200] loss: 1.270\n","[1, 38400] loss: 1.281\n","[1, 38600] loss: 1.273\n","[1, 38800] loss: 1.275\n","[1, 39000] loss: 1.280\n","[1, 39200] loss: 1.265\n","[1, 39400] loss: 1.270\n","[1, 39600] loss: 1.263\n","[1, 39800] loss: 1.260\n","[1, 40000] loss: 1.270\n","[1, 40200] loss: 1.263\n","[1, 40400] loss: 1.260\n","[1, 40600] loss: 1.268\n","[1, 40800] loss: 1.259\n","[1, 41000] loss: 1.263\n","[1, 41200] loss: 1.267\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-5-4a16b7e55f2e\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Model/NetBT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, trainset, save_file, dev, saves, prints, lr, iter, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 48\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprints\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprints\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m               print('[%d, %5d] loss: %.3f' %\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["training.train_model(net,trainset,save_file = \"/content/drive/MyDrive/Model/NetBT\", batch_size = 100, lr = 0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xn7eYOo23Bt-"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   200] loss: 1.241\n","[1,   400] loss: 1.232\n","[1,   600] loss: 1.242\n","[1,   800] loss: 1.238\n","[1,  1000] loss: 1.237\n","[1,  1200] loss: 1.249\n","[1,  1400] loss: 1.236\n","[1,  1600] loss: 1.219\n","[1,  1800] loss: 1.223\n","[1,  2000] loss: 1.235\n","[1,  2200] loss: 1.239\n","[1,  2400] loss: 1.237\n","[1,  2600] loss: 1.229\n","[1,  2800] loss: 1.223\n","[1,  3000] loss: 1.238\n","[1,  3200] loss: 1.235\n","[1,  3400] loss: 1.227\n","[1,  3600] loss: 1.231\n","[1,  3800] loss: 1.227\n","[1,  4000] loss: 1.229\n","[1,  4200] loss: 1.243\n","[1,  4400] loss: 1.236\n","[1,  4600] loss: 1.214\n","[1,  4800] loss: 1.220\n","[1,  5000] loss: 1.232\n","[1,  5200] loss: 1.218\n","[1,  5400] loss: 1.227\n","[1,  5600] loss: 1.229\n","[1,  5800] loss: 1.224\n","[1,  6000] loss: 1.221\n","[1,  6200] loss: 1.220\n","[1,  6400] loss: 1.215\n","[1,  6600] loss: 1.222\n","[1,  6800] loss: 1.223\n","[1,  7000] loss: 1.207\n","[1,  7200] loss: 1.215\n","[1,  7400] loss: 1.234\n","[1,  7600] loss: 1.209\n","[1,  7800] loss: 1.209\n","[1,  8000] loss: 1.217\n","[1,  8200] loss: 1.220\n","[1,  8400] loss: 1.223\n","[1,  8600] loss: 1.218\n","[1,  8800] loss: 1.214\n","[1,  9000] loss: 1.210\n","[1,  9200] loss: 1.213\n","[1,  9400] loss: 1.202\n","[1,  9600] loss: 1.208\n","[1,  9800] loss: 1.207\n","[1, 10000] loss: 1.206\n","[1, 10200] loss: 1.228\n","[1, 10400] loss: 1.204\n","[1, 10600] loss: 1.209\n","[1, 10800] loss: 1.203\n","[1, 11000] loss: 1.208\n","[1, 11200] loss: 1.213\n","[1, 11400] loss: 1.209\n","[1, 11600] loss: 1.204\n","[1, 11800] loss: 1.208\n","[1, 12000] loss: 1.193\n","[1, 12200] loss: 1.202\n","[1, 12400] loss: 1.209\n","[1, 12600] loss: 1.211\n","[1, 12800] loss: 1.202\n","[1, 13000] loss: 1.201\n","[1, 13200] loss: 1.205\n","[1, 13400] loss: 1.197\n","[1, 13600] loss: 1.195\n","[1, 13800] loss: 1.196\n","[1, 14000] loss: 1.205\n","[1, 14200] loss: 1.196\n","[1, 14400] loss: 1.202\n","[1, 14600] loss: 1.188\n","[1, 14800] loss: 1.199\n","[1, 15000] loss: 1.194\n","[1, 15200] loss: 1.202\n","[1, 15400] loss: 1.184\n","[1, 15600] loss: 1.185\n","[1, 15800] loss: 1.196\n","[1, 16000] loss: 1.202\n","[1, 16200] loss: 1.195\n","[1, 16400] loss: 1.187\n","[1, 16600] loss: 1.201\n","[1, 16800] loss: 1.192\n","[1, 17000] loss: 1.191\n","[1, 17200] loss: 1.206\n","[1, 17400] loss: 1.187\n","[1, 17600] loss: 1.195\n","[1, 17800] loss: 1.183\n","[1, 18000] loss: 1.196\n","[1, 18200] loss: 1.193\n"]}],"source":["training.train_model_load(net,trainset,save_file = \"/content/drive/MyDrive/Model/NetBT\", batch_size = 100, lr = 0.00005)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","name":"","provenance":[{"file_id":"1a6ZXyviUEmXDLu7bjAoLyMWY4jNVZZUk","timestamp":1714002906782}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}