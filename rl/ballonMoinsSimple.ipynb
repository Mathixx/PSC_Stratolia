{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import torch \n",
    "\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from typing import List, Tuple\n",
    "from matplotlib import animation\n",
    "\n",
    "import collections\n",
    "from collections import namedtuple, deque\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "class balloon3D:\n",
    "    def __init__(self,width,length,height,obs_size):\n",
    "        self.obs_size = obs_size\n",
    "        self.x, self.y , self.z = 0,0,0\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.length = length\n",
    "        self.map = None\n",
    "\n",
    "    def reset(self,start_x,start_y,start_z):\n",
    "        self.x, self.y ,self.z = start_x,start_y,start_z\n",
    "\n",
    "    def up(self):\n",
    "        self.z = min(self.height-1,self.z+1)\n",
    "\n",
    "    def down(self):\n",
    "        self.z = max(self.z-1,0)\n",
    "\n",
    "    def step(self):\n",
    "        newx = int((self.x + self.map[self.x,self.y,self.z,0]) % self.width)\n",
    "        newy = int((self.y + self.map[self.x,self.y,self.z,1]) % self.length)\n",
    "        self.x = newx\n",
    "        self.y = newy\n",
    "\n",
    "    def generate_map(self,eta,mu):\n",
    "        self.map = np.zeros((self.width,self.length,self.height,2))\n",
    "        for i in range(self.width):\n",
    "            for j in  range(self.length):\n",
    "                for k in range(self.height):\n",
    "                    for l in range(2):\n",
    "                        r = np.random.random()\n",
    "                        if(r>eta):\n",
    "                            r= np.random.random()\n",
    "                            if(r>mu):\n",
    "                                self.map[i,j,k,l] = 1\n",
    "                            else:\n",
    "                                self.map[i,j,k,l] = -1\n",
    "\n",
    "\n",
    "    def set_map(self,map):\n",
    "        self.map = map\n",
    "\n",
    "    def get_winds(self):\n",
    "        r = self.obs_size\n",
    "        self.obs = np.zeros((2*r+1,2*r+1,self.height,2))\n",
    "        for i in range(self.x - r , self.x + r + 1):\n",
    "            for j in range(self.y - r, self.y + r + 1):\n",
    "                for k in range(0,self.height):\n",
    "                    for l in range(2):\n",
    "                        self.obs[i - self.x + r, j- self.y + r,k,l]  = (self.map[i%self.width,j%self.length,k,l])\n",
    "        return self.obs\n",
    "    \n",
    "    def render_obs(self):\n",
    "        r =self.obs_size*2+1\n",
    "        for z in range(self.height):\n",
    "            for j in range(r):\n",
    "                s = ''\n",
    "                for i in range(r):\n",
    "                    l = ''\n",
    "                    if(self.obs[i,j,z,0] == 0):\n",
    "                        l += '.'\n",
    "                    elif(self.obs[i,j,z,0] == 1):\n",
    "                        l+='>'\n",
    "                    elif(self.obs[i,j,z,0] == -1):\n",
    "                        l+='<'\n",
    "\n",
    "                    if(self.obs[i,j,z,1] == 0):\n",
    "                        l += '.'\n",
    "                    elif(self.obs[i,j,z,1] == 1):\n",
    "                        l+='v'\n",
    "                    elif(self.obs[i,j,z,1] == -1):\n",
    "                        l+='^'                  \n",
    "                    s+= l+ \" \"\n",
    "                print(s)\n",
    "            print(\" \")\n",
    "    \n",
    "\n",
    "    \n",
    "    def render(self):\n",
    "        for z in range(self.height):\n",
    "            for j in range(self.length):\n",
    "                s = ''\n",
    "                for i in range(self.width):\n",
    "                    if self.x == i and self.y == j and self.z == z : \n",
    "                        s+= 'OO '\n",
    "                    else:\n",
    "                        l = ''\n",
    "                        if(self.map[i,j,z,0] == 0):\n",
    "                            l += '.'\n",
    "                        elif(self.map[i,j,z,0] == 1):\n",
    "                            l+='>'\n",
    "                        elif(self.map[i,j,z,0] == -1):\n",
    "                            l+='<'\n",
    "\n",
    "                        if(self.map[i,j,z,1] == 0):\n",
    "                            l += '.'\n",
    "                        elif(self.map[i,j,z,1] == 1):\n",
    "                            l+='v'\n",
    "                        elif(self.map[i,j,z,1] == -1):\n",
    "                            l+='^'\n",
    "                        \n",
    "                        s+= l+ \" \"\n",
    "                print(s)\n",
    "            print(\" \")\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OO <^ >v >. .. \n",
      "<v <^ .v .. <. \n",
      ".. >. >^ .^ .^ \n",
      ".v .^ .. .. <v \n",
      "<v >v .. .^ .. \n",
      " \n",
      ".^ .. .. .. .^ \n",
      ".. .v >. >^ <v \n",
      "<^ <v >. .. .v \n",
      "<^ <. >v .. <. \n",
      ">v .. .v .^ >. \n",
      " \n",
      ">. >^ <. >v <. \n",
      ".v .. >^ >. .. \n",
      ".^ .v >. .^ .v \n",
      "<. .. >. >. >. \n",
      ".. .^ .. >. .. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "bal = balloon3D(5,5,3,2)\n",
    "bal.generate_map(0.5,0.5)\n",
    "bal.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">^ <^ >v >. .. \n",
      "<v <^ .v .. <. \n",
      ".. >. >^ .^ .^ \n",
      ".v .^ .. .. <v \n",
      "<v OO .. .^ .. \n",
      " \n",
      ".^ .. .. .. .^ \n",
      ".. .v >. >^ <v \n",
      "<^ <v >. .. .v \n",
      "<^ <. >v .. <. \n",
      ">v .. .v .^ >. \n",
      " \n",
      ">. >^ <. >v <. \n",
      ".v .. >^ >. .. \n",
      ".^ .v >. .^ .v \n",
      "<. .. >. >. >. \n",
      ".. .^ .. >. .. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "bal.step()\n",
    "bal.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".^ .. . ^ .^ \n",
      ">v .v .^ .. .. \n",
      ".. >v v .. .^ \n",
      ".. ^ <^ v >. \n",
      ">. >v >^ .v .. \n",
      " \n",
      ".v <^ <v >. .. \n",
      ">. <^ >. >v .. \n",
      ". v .. .v .^ \n",
      ".^ .^ .. .. .. \n",
      "<v .. .v . ^ \n",
      " \n",
      ".v .^ .v >. .^ \n",
      ". >. .. . . \n",
      ".. .. .^ .. . \n",
      "<. . ^ <. v \n",
      ".. .v .. >^ . \n",
      " \n"
     ]
    }
   ],
   "source": [
    "bal.get_winds()\n",
    "bal.redner_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalEnv(gym.Env):\n",
    "    def __init__(self, render_mode=None, s_x = 10 , s_y =10 , s_z = 3, obs_size = 5 ):\n",
    "        self.balloon = balloon3D(s_x,s_y,s_z,obs_size)\n",
    "        self.obs_size = obs_size\n",
    "\n",
    "        self._target_location = [s_x-1,s_y-1,s_z-1]\n",
    "\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location.\n",
    "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                #\"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                #\"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"map\": spaces.Box(-1, 1, shape=(2*obs_size + 1,obs_size*2+1,s_z,2), dtype=int),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "    def reset(self):\n",
    "        self.evo_time = 100\n",
    "\n",
    "        self.reward = 0\n",
    "\n",
    "        self.reward_x, self.reward_y = 0,0\n",
    "\n",
    "        self.balloon.generate_map(0.35,0.5)\n",
    "\n",
    "        self.time = 0\n",
    "\n",
    "        self.balloon.reset(0,0,0)\n",
    "\n",
    "        self._agent_location = [0,0,0]\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        self.time += 1\n",
    "\n",
    "        if action == 0:\n",
    "            self.balloon.map[self.balloon.x , self.balloon.y,self.balloon.z,0] +  self.balloon.map[self.balloon.x , self.balloon.y,self.balloon.z,1] \n",
    "            self.balloon.step()\n",
    "        if action == 1:\n",
    "            self.balloon.up()\n",
    "        if action == 2:\n",
    "            self.balloon.down()\n",
    "\n",
    "\n",
    "        \n",
    "        self._agent_location = np.array([self.balloon.x , self.balloon.y,self.balloon.z])\n",
    "        terminated  = ((self._agent_location[0]==self._target_location[0])and(self._agent_location[1]==self._target_location[1]))\n",
    "        \n",
    "        distx = min(((self._agent_location[0] - self._target_location[0])%self.balloon.width),(self._target_location[0] - self._agent_location[0])%self.balloon.width)\n",
    "        disty = min(((self._agent_location[1] - self._target_location[1])%self.balloon.length),(self._target_location[1] - self._agent_location[1])%self.balloon.length)\n",
    "\n",
    "\n",
    "\n",
    "        self.reward = -(np.sqrt((distx)**2 + (disty)**2))\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation, self.reward, terminated, False, {}\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        return {\"map\" : self.balloon.get_winds()}\n",
    "\n",
    "    def render(self):\n",
    "        self.balloon.render()\n",
    "        \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'map': array([[[[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [ 0.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1.,  0.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [-1.,  0.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[ 0.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 0.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 0.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 0.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1.,  0.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1.,  0.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 0.,  1.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 1.,  1.],\n",
       "           [-1.,  0.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1.,  1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[ 0.,  0.],\n",
       "           [ 0., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 0.,  1.],\n",
       "           [-1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1.,  0.],\n",
       "           [ 1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1.,  0.],\n",
       "           [-1., -1.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [ 1.,  0.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 1., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 0.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 0.,  1.],\n",
       "           [ 0.,  1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1.,  0.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [ 0.,  0.]],\n",
       "  \n",
       "          [[ 0.,  0.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [ 0.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 0.,  1.],\n",
       "           [ 0., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 0.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [ 0.,  0.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [-1., -1.],\n",
       "           [ 0.,  0.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  0.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.,  0.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 0.,  0.],\n",
       "           [ 0.,  1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [-1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [-1.,  1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 0.,  0.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [-1., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0.,  0.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[ 1.,  0.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [ 0.,  0.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 1., -1.],\n",
       "           [ 0.,  0.]],\n",
       "  \n",
       "          [[ 0.,  0.],\n",
       "           [-1.,  1.],\n",
       "           [ 0.,  0.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1.,  1.],\n",
       "           [ 0., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 1., -1.],\n",
       "           [ 0.,  0.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [ 1.,  1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 0.,  0.],\n",
       "           [ 1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [ 0., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [-1.,  1.],\n",
       "           [ 0., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [-1., -1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1.,  1.]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [-1.,  1.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [ 0.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1., -1.],\n",
       "           [ 0., -1.],\n",
       "           [ 1., -1.]],\n",
       "  \n",
       "          [[-1.,  1.],\n",
       "           [ 1.,  0.],\n",
       "           [-1., -1.]],\n",
       "  \n",
       "          [[ 1.,  1.],\n",
       "           [-1., -1.],\n",
       "           [-1.,  0.]],\n",
       "  \n",
       "          [[ 0., -1.],\n",
       "           [-1.,  0.],\n",
       "           [ 1.,  0.]],\n",
       "  \n",
       "          [[ 0.,  1.],\n",
       "           [ 0., -1.],\n",
       "           [-1.,  1.]],\n",
       "  \n",
       "          [[-1.,  0.],\n",
       "           [ 1.,  1.],\n",
       "           [-1.,  1.]]]])},\n",
       " {})"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BalEnv()\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<v <. .^ <^ <v <^ <^ <^ >v <^ \n",
      ">^ <. >^ >^ <^ <v <. <^ <^ >^ \n",
      "<^ >v >v <^ <. >v >^ .. <. <. \n",
      ">v <v <^ >v >v .^ .^ .v .v >^ \n",
      "<. <v >. <^ >^ .v >^ >. <^ <v \n",
      "<^ <. <^ <^ >^ <. <v >v <^ >v \n",
      ">v <^ >^ >v >v <. >^ >v .^ .. \n",
      "<v <^ >^ .. <v <v .v <v >^ >v \n",
      ">. <^ <v <^ <v <. >^ <. <^ >^ \n",
      ".^ .. <^ <v <v <. >^ <v .^ >v \n",
      " \n",
      "<^ <^ <^ >v .^ OO >^ >v >^ .. \n",
      "<^ <v .^ <v <v >. <v >v >v >^ \n",
      ".. .. <. >^ .^ <^ >v .^ .v .v \n",
      ">^ >. .. .^ <^ <. <^ <^ .v .v \n",
      "<v <^ <^ >^ <^ .^ <. >^ <. <v \n",
      "<v .^ .^ >^ .^ >v <v <. <^ .^ \n",
      "<v <. <^ >^ >v >^ >v <v .^ <^ \n",
      ">^ <^ <v <v >^ <v <v >v <^ <v \n",
      ">v >v >v .v .. >v <. .^ .^ .^ \n",
      "<^ .v >^ <v .^ >v <v <v >. .^ \n",
      " \n",
      "<^ >^ >^ .^ >^ >^ >. <. >v >v \n",
      "<v <. >^ <^ .^ <^ >. <v <^ >^ \n",
      ">v >. >v <^ <v <. <^ >^ <^ .^ \n",
      "<^ >v >^ <. <^ >. <. >^ >^ <^ \n",
      "<v <^ <v <v <^ <v <v >^ <^ <v \n",
      "<. >v >v .. >v <v .v <^ <^ .. \n",
      "<v >v >^ .. >^ <v <. >. <v <^ \n",
      ">v <v >. .. <v <^ .v >^ >^ >v \n",
      "<v <^ <^ <^ >v .v >. <v <^ >v \n",
      ".. >. <. >v .^ <v >. <^ >^ .v \n",
      " \n",
      "-4.123105625617661\n"
     ]
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "print(a)\n",
    "_,r,_,_,_ = env.step(a)\n",
    "env.render()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FullyConnectedModel, self).__init__()\n",
    "        self.soft = torch.nn.Softmax(dim = -1)\n",
    "        # Define layers with ReLU activation\n",
    "        self.linear1 = nn.Linear(input_size, 30)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(30, 30)\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(30, 30)\n",
    "        self.activation3 = nn.Sigmoid()\n",
    "\n",
    "        # Output layer without activation function\n",
    "        self.output_layer = nn.Linear(30, output_size)\n",
    "\n",
    "        # Initialization using Xavier uniform (a popular technique for initializing weights in NNs)\n",
    "        nn.init.xavier_normal_(self.linear1.weight)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "        nn.init.xavier_normal_(self.linear3.weight)\n",
    "        nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward pass through the layers\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.soft(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "class QNetwork:\n",
    "    def __init__(self, env, lr, logdir=None):\n",
    "        # Define Q-network with specified architecture\n",
    "        self.net = FullyConnectedModel(4, 2)\n",
    "        self.env = env\n",
    "        self.lr = lr \n",
    "        self.logdir = logdir\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        # Load pre-trained model from a file\n",
    "        return self.net.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def load_model_weights(self, weight_file):\n",
    "        # Load pre-trained model weights from a file\n",
    "        return self.net.load_state_dict(torch.load(weight_file))\n",
    "    \n",
    "class QPolicy:\n",
    "    def __init__(self, s_size, a_size):\n",
    "        self.net = FullyConnectedModel(s_size,a_size)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.tensor(state)\n",
    "        probs = self.net(state)\n",
    "        m = torch.distributions.Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every,env):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_training_episodes + 1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state, _ = env.reset()\n",
    "        for t in range(max_t):\n",
    "            action, log_prob = policy.act(torch.tensor(state,dtype=torch.double))\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, truncated , _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done or truncated:\n",
    "                break\n",
    "        scores_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        returns = deque(maxlen=max_t)\n",
    "        n_steps = len(rewards)\n",
    "        for t in range(n_steps)[::-1]:\n",
    "            disc_return_t = returns[0] if len(returns) > 0 else 0\n",
    "            returns.appendleft(gamma * disc_return_t + rewards[t])\n",
    "\n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "        returns = torch.tensor(returns)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "\n",
    "\n",
    "        policy_loss = 0\n",
    "        for log_prob, disc_return in zip(saved_log_probs, returns):\n",
    "            policy_loss += (-log_prob * disc_return)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "        print(policy.net.linear1.weight.grad)\n",
    "        if i_episode % print_every == 0:\n",
    "            print(\"Episode {}\\tAverage Score: {:.2f}\".format(i_episode, np.mean(scores_deque)))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create policy and place it to the device\n",
    "\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_training_episodes\": 100,\n",
    "    \"n_evaluation_episodes\": 10,\n",
    "    \"max_t\": 30,\n",
    "    \"gamma\": 1.0,\n",
    "    \"lr\": 1e-2,\n",
    "    \"grid_size\" : 5,\n",
    "    \"obs_r\" :2,\n",
    "    \"action_space\": 3,\n",
    "    \"print\" : 1\n",
    "}\n",
    "\n",
    "policy = QPolicy(\n",
    "    ((hyperparameters[\"obs_r\"]*2+1)**2)*2*3,hyperparameters[\"action_space\"]\n",
    ")\n",
    "optimizer = optim.Adam(policy.net.parameters(), lr=hyperparameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: -54.25\n",
      "tensor([[-0.0019,  0.0009, -0.0019,  ..., -0.0033,  0.0038, -0.0005],\n",
      "        [-0.0090,  0.0019, -0.0101,  ..., -0.0123,  0.0132, -0.0011],\n",
      "        [-0.0086, -0.0034,  0.0019,  ..., -0.0047,  0.0014,  0.0032],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0033, -0.0018,  ...,  0.0052, -0.0021, -0.0031],\n",
      "        [-0.0078, -0.0044,  0.0043,  ..., -0.0026, -0.0015,  0.0040],\n",
      "        [ 0.0105,  0.0017,  0.0047,  ...,  0.0095, -0.0073, -0.0021]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monce\\AppData\\Local\\Temp\\ipykernel_18956\\1435207334.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state)\n"
     ]
    }
   ],
   "source": [
    "env = BalEnv(obs_size=hyperparameters[\"obs_r\"])\n",
    "wrapped_env = FlattenObservation(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monce\\AppData\\Local\\Temp\\ipykernel_18956\\1435207334.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0034,  0.0113, -0.0185,  ...,  0.0154,  0.0165, -0.0091],\n",
      "        [-0.0001, -0.0045,  0.0072,  ..., -0.0047, -0.0057,  0.0026],\n",
      "        [-0.0039, -0.0031,  0.0064,  ..., -0.0067, -0.0067,  0.0031],\n",
      "        ...,\n",
      "        [-0.0017,  0.0040, -0.0066,  ...,  0.0031,  0.0043, -0.0015],\n",
      "        [ 0.0008, -0.0025,  0.0041,  ..., -0.0016, -0.0026,  0.0005],\n",
      "        [ 0.0003,  0.0012, -0.0019,  ...,  0.0016,  0.0017, -0.0010]])\n",
      "Episode 1\tAverage Score: -19.84\n",
      "tensor([[-9.4916e-03, -2.1056e-02,  2.9385e-04,  ..., -1.2353e-02,\n",
      "          1.1586e-03,  6.2983e-03],\n",
      "        [ 5.9562e-03,  1.8235e-02,  1.1367e-05,  ...,  1.2769e-02,\n",
      "         -3.5264e-03, -4.4532e-03],\n",
      "        [ 8.0368e-04,  1.0590e-02, -1.6922e-03,  ...,  8.9573e-03,\n",
      "          3.1273e-03, -8.5786e-04],\n",
      "        ...,\n",
      "        [-4.8650e-03, -8.5564e-03,  1.4294e-03,  ..., -5.6652e-03,\n",
      "          8.3277e-03,  6.9602e-03],\n",
      "        [ 6.0479e-03,  1.4519e-02, -3.2322e-04,  ...,  1.2047e-02,\n",
      "         -7.1740e-03, -5.3334e-03],\n",
      "        [ 6.8579e-04,  2.2301e-03,  4.6538e-04,  ...,  1.2535e-03,\n",
      "         -6.2531e-04, -3.2274e-04]])\n",
      "Episode 2\tAverage Score: -67.39\n",
      "tensor([[-0.0019, -0.0191, -0.0173,  ..., -0.0192, -0.0211,  0.0172],\n",
      "        [-0.0011,  0.0136,  0.0147,  ...,  0.0114,  0.0168, -0.0125],\n",
      "        [ 0.0040,  0.0058, -0.0005,  ...,  0.0070,  0.0030, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0050, -0.0005,  ...,  0.0074,  0.0005, -0.0036],\n",
      "        [-0.0048,  0.0054,  0.0131,  ...,  0.0018,  0.0137, -0.0066],\n",
      "        [-0.0012,  0.0028,  0.0041,  ...,  0.0014,  0.0046, -0.0026]])\n",
      "Episode 3\tAverage Score: -55.71\n",
      "tensor([[-1.4557e-02,  9.0995e-03, -2.2433e-02,  ..., -1.8193e-02,\n",
      "          7.6993e-03,  1.4181e-03],\n",
      "        [ 1.0530e-02, -8.4532e-03,  1.7244e-02,  ...,  1.7867e-02,\n",
      "         -9.0716e-03, -3.4513e-03],\n",
      "        [ 1.2792e-02, -6.9056e-03,  1.4407e-02,  ...,  4.0906e-03,\n",
      "         -3.2280e-03, -5.2716e-03],\n",
      "        ...,\n",
      "        [ 1.0563e-03, -1.6635e-04, -2.4002e-03,  ..., -4.6728e-03,\n",
      "          1.3355e-03,  5.8922e-05],\n",
      "        [ 6.9651e-03, -5.0219e-03,  1.8141e-02,  ...,  1.7682e-02,\n",
      "         -6.3211e-03, -2.1248e-03],\n",
      "        [ 4.9047e-03, -1.9604e-03,  6.1462e-03,  ...,  5.1744e-03,\n",
      "         -8.2755e-04,  1.1929e-03]])\n",
      "Episode 4\tAverage Score: -72.10\n",
      "tensor([[-3.8525e-03,  3.3345e-03, -4.8726e-03,  ...,  7.5541e-03,\n",
      "          4.9878e-03, -1.4798e-02],\n",
      "        [ 4.0877e-03, -3.1453e-03, -2.7507e-05,  ..., -1.5449e-03,\n",
      "         -1.9767e-03,  6.5884e-03],\n",
      "        [ 9.0966e-05,  1.5106e-04,  6.0212e-03,  ..., -5.1891e-03,\n",
      "         -7.7666e-03,  9.7526e-03],\n",
      "        ...,\n",
      "        [-1.6090e-03,  1.0334e-03,  1.2520e-03,  ..., -6.8411e-05,\n",
      "          7.4342e-05, -3.5190e-04],\n",
      "        [ 5.8068e-03, -6.3051e-03, -1.9697e-03,  ..., -1.9347e-03,\n",
      "         -2.2582e-03,  6.4791e-03],\n",
      "        [ 1.6840e-03, -2.6047e-03,  5.3152e-05,  ..., -1.8622e-03,\n",
      "         -1.1743e-03,  4.0717e-03]])\n",
      "Episode 5\tAverage Score: -77.11\n",
      "tensor([[-1.6076e-03, -5.1165e-03,  2.4336e-03,  ..., -1.0666e-03,\n",
      "         -7.3780e-03,  1.4880e-03],\n",
      "        [-6.5454e-03,  5.8634e-04,  2.4716e-04,  ...,  2.2902e-04,\n",
      "         -1.6715e-03, -3.3204e-03],\n",
      "        [ 7.4490e-03,  2.8088e-03,  2.4914e-03,  ...,  1.0677e-03,\n",
      "          1.0061e-02,  8.8473e-04],\n",
      "        ...,\n",
      "        [ 1.7350e-03, -2.7484e-04, -3.3251e-04,  ...,  2.2217e-04,\n",
      "          6.4768e-04,  1.3077e-03],\n",
      "        [-1.2512e-02,  1.0689e-04, -2.2864e-03,  ...,  9.6750e-05,\n",
      "         -5.8726e-03, -3.8967e-03],\n",
      "        [-4.9484e-03,  4.8878e-04, -6.3992e-04,  ...,  1.7755e-04,\n",
      "         -1.6321e-03, -2.1473e-03]])\n",
      "Episode 6\tAverage Score: -81.54\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "Episode 7\tAverage Score: -69.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monce\\AppData\\Local\\Temp\\ipykernel_18956\\4275045381.py:26: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1760.)\n",
      "  returns = (returns - returns.mean()) / (returns.std() + eps)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([nan, nan, nan], grad_fn=<DivBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1021], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mreinforce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_training_episodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgamma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1017], line 9\u001b[0m, in \u001b[0;36mreinforce\u001b[1;34m(policy, optimizer, n_training_episodes, max_t, gamma, print_every, env)\u001b[0m\n\u001b[0;32m      7\u001b[0m state, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_t):\n\u001b[1;32m----> 9\u001b[0m     action, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     saved_log_probs\u001b[38;5;241m.\u001b[39mappend(log_prob)\n\u001b[0;32m     11\u001b[0m     state, reward, done, truncated , _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "Cell \u001b[1;32mIn[965], line 55\u001b[0m, in \u001b[0;36mQPolicy.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     53\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state)\n\u001b[0;32m     54\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(state)\n\u001b[1;32m---> 55\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m action \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem(), m\u001b[38;5;241m.\u001b[39mlog_prob(action)\n",
      "File \u001b[1;32mc:\\Users\\monce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\distributions\\categorical.py:70\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     67\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m     69\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\monce\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\distributions\\distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([nan, nan, nan], grad_fn=<DivBackward0>)"
     ]
    }
   ],
   "source": [
    "scores = reinforce(\n",
    "    policy,\n",
    "    optimizer,\n",
    "    hyperparameters[\"n_training_episodes\"],\n",
    "    hyperparameters[\"max_t\"],\n",
    "    hyperparameters[\"gamma\"],\n",
    "    hyperparameters[\"print\"],\n",
    "    wrapped_env)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
